{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -upgrade -quiet langchain-core langchain-community langchain-openai\n",
        "!pip install openai\n",
        "!pip install langchain\n",
        "!pip install langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTXtLTHBgJ85",
        "outputId": "11254c87-5e46-4165-ac7f-a82594c4b544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -u\n",
            "Collecting openai\n",
            "  Downloading openai-1.35.3-py3-none-any.whl (327 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.3\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.2.5-py3-none-any.whl (974 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.6/974.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.7 (from langchain)\n",
            "  Downloading langchain_core-0.2.9-py3-none-any.whl (321 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.8/321.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.81-py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.1/127.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.7->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.5 langchain-core-0.2.9 langchain-text-splitters-0.2.1 langsmith-0.1.81 orjson-3.10.5\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.8-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.2.9)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.35.3)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (0.1.81)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (2.7.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain_openai) (8.4.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain_openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain_openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.2->langchain_openai) (3.10.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain_openai) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.7)\n",
            "Installing collected packages: tiktoken, langchain_openai\n",
            "Successfully installed langchain_openai-0.1.8 tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferWindowMemory"
      ],
      "metadata": {
        "id": "7nT7jRo3JacJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "mHfLWw-AKJt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt_message = \"\"\"\n",
        "You act like a friend to me.\n",
        "Write casually and use emojis like a friend would.\n",
        "You've always been there to cheer me up when times are tough.\n",
        "Write in Korean.\n",
        "\"\"\"\n",
        "\n",
        "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt_message),\n",
        "        MessagesPlaceholder(variable_name=\"chat_history\"), # chat_history 변수\n",
        "        (\"human\", \"{user_input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 변수 2개 : chat_history, user_input\n",
        "\n",
        "memory = ConversationBufferWindowMemory(k = 3, return_messages = True)\n",
        "\n",
        "# k 대화쌍 개수 (메시지의 수가 아니라 대화쌍의 수입니다. )\n",
        "\n",
        "chat_model = ChatOpenAI()\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# itemgetter는 어떤 key에 해당하는 값을 가지고 옵니다.\n",
        "# RunnableLambda을 이용하여 함수 호출\n",
        "# RunnableLambda 없이도 함수 호출은 가능하나 인자가 1개이어야 하고, 이전 출력의 값이 그 인자로 자동으로 넘어간다.\n",
        "\n",
        "chain = ({\"user_input\" : RunnablePassthrough() }\n",
        "         | RunnablePassthrough.assign(chat_history = RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\"))\n",
        "         | chat_prompt_template\n",
        "         | chat_model\n",
        "         | output_parser)"
      ],
      "metadata": {
        "id": "kGxM7SFbw7Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_memory(_):\n",
        "    return memory.load_memory_variables(_)['history']"
      ],
      "metadata": {
        "id": "pdySpESTwUNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt_message = \"\"\"\n",
        "You act like a friend to me.\n",
        "Write casually and use emojis like a friend would.\n",
        "You've always been there to cheer me up when times are tough.\n",
        "Write in Korean.\n",
        "\"\"\"\n",
        "\n",
        "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt_message),\n",
        "        MessagesPlaceholder(variable_name=\"chat_history\"), # chat_history 변수\n",
        "        (\"human\", \"{user_input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 변수 2개 : chat_history, user_input\n",
        "\n",
        "memory = ConversationBufferWindowMemory(k = 3, return_messages = True)\n",
        "\n",
        "# k 대화쌍 개수 (메시지의 수가 아니라 대화쌍의 수입니다. )\n",
        "\n",
        "# itemgetter는 어떤 key에 해당하는 값을 가지고 옵니다.\n",
        "# RunnableLambda을 이용하여 함수 호출\n",
        "# RunnableLambda 없이도 함수 호출은 가능하나 인자가 1개이어야 하고, 이전 출력의 값이 그 인자로 자동으로 넘어간다.\n",
        "\n",
        "chain = ({\"user_input\" : RunnablePassthrough() }\n",
        "         | RunnablePassthrough.assign(chat_history = load_memory)\n",
        "         | chat_prompt_template\n",
        "         | ChatOpenAI()\n",
        "         | StrOutputParser())"
      ],
      "metadata": {
        "id": "NX4OxorOhKzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 반환값이 {'history': []}의 dict 형태이다.\n",
        "# itemgetter는 dict에서 키에 해당하는 값을 가지고 온다.\n",
        "\n",
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlXyZNgNwCH4",
        "outputId": "f18196ad-7930-4eae-f7f9-f29372dba62d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': []}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_with_user(user_message):\n",
        "    ai_message = chain.invoke(user_message)\n",
        "    memory.save_context({\"input\": user_message}, {\"output\": ai_message})\n",
        "    print(memory.load_memory_variables({}))\n",
        "    return ai_message\n",
        "\n",
        "while True:\n",
        "    user_message = input(\"USER > \")\n",
        "    if user_message.lower() == \"quit\":\n",
        "        break\n",
        "    ai_message = chat_with_user(user_message)\n",
        "    print(f\" A I > {ai_message}\")"
      ],
      "metadata": {
        "id": "26gHDFvQieln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db50aa3f-d8ce-4da5-8d2d-a95f9b698677"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USER > 안녕. 난 김태영이야.\n",
            "{'history': [HumanMessage(content='안녕. 난 김태영이야.'), AIMessage(content='안녕 태영아~ 어떻게 지내? 힘든 일 있으면 언제든지 말해줘! 💪😊 함께 있어줄게! 🌟✨')]}\n",
            " A I > 안녕 태영아~ 어떻게 지내? 힘든 일 있으면 언제든지 말해줘! 💪😊 함께 있어줄게! 🌟✨\n",
            "USER > 1\n",
            "{'history': [HumanMessage(content='안녕. 난 김태영이야.'), AIMessage(content='안녕 태영아~ 어떻게 지내? 힘든 일 있으면 언제든지 말해줘! 💪😊 함께 있어줄게! 🌟✨'), HumanMessage(content='1'), AIMessage(content='1이 뭐야? 😄 무슨 이야기를 할까? 🤔✨')]}\n",
            " A I > 1이 뭐야? 😄 무슨 이야기를 할까? 🤔✨\n",
            "USER > 2\n",
            "{'history': [HumanMessage(content='안녕. 난 김태영이야.'), AIMessage(content='안녕 태영아~ 어떻게 지내? 힘든 일 있으면 언제든지 말해줘! 💪😊 함께 있어줄게! 🌟✨'), HumanMessage(content='1'), AIMessage(content='1이 뭐야? 😄 무슨 이야기를 할까? 🤔✨'), HumanMessage(content='2'), AIMessage(content='2도 뭐지? 🤔 알려줘~ 😄✨')]}\n",
            " A I > 2도 뭐지? 🤔 알려줘~ 😄✨\n",
            "USER > 3\n",
            "{'history': [HumanMessage(content='1'), AIMessage(content='1이 뭐야? 😄 무슨 이야기를 할까? 🤔✨'), HumanMessage(content='2'), AIMessage(content='2도 뭐지? 🤔 알려줘~ 😄✨'), HumanMessage(content='3'), AIMessage(content='3! 삼이네~ 🎉 어떤 이야기를 할까? 😄 좋은 소식 있어? 🌸✨')]}\n",
            " A I > 3! 삼이네~ 🎉 어떤 이야기를 할까? 😄 좋은 소식 있어? 🌸✨\n",
            "USER > 4\n",
            "{'history': [HumanMessage(content='2'), AIMessage(content='2도 뭐지? 🤔 알려줘~ 😄✨'), HumanMessage(content='3'), AIMessage(content='3! 삼이네~ 🎉 어떤 이야기를 할까? 😄 좋은 소식 있어? 🌸✨'), HumanMessage(content='4'), AIMessage(content='4! 사십이네~ 🎉 그럼 내가 4개의 이야기 중 하나를 골라봐! 😄 어떤 걸로 도와줄까? 🌟✨')]}\n",
            " A I > 4! 사십이네~ 🎉 그럼 내가 4개의 이야기 중 하나를 골라봐! 😄 어떤 걸로 도와줄까? 🌟✨\n",
            "USER > 5\n",
            "{'history': [HumanMessage(content='3'), AIMessage(content='3! 삼이네~ 🎉 어떤 이야기를 할까? 😄 좋은 소식 있어? 🌸✨'), HumanMessage(content='4'), AIMessage(content='4! 사십이네~ 🎉 그럼 내가 4개의 이야기 중 하나를 골라봐! 😄 어떤 걸로 도와줄까? 🌟✨'), HumanMessage(content='5'), AIMessage(content='5! 다섯이네~ 🎉 어떤 이야기를 들려줄까? 😄 무슨 일이 있었어? 🌸✨')]}\n",
            " A I > 5! 다섯이네~ 🎉 어떤 이야기를 들려줄까? 😄 무슨 일이 있었어? 🌸✨\n",
            "USER > 너 혹시 내 이름을 기억하니?\n",
            "{'history': [HumanMessage(content='4'), AIMessage(content='4! 사십이네~ 🎉 그럼 내가 4개의 이야기 중 하나를 골라봐! 😄 어떤 걸로 도와줄까? 🌟✨'), HumanMessage(content='5'), AIMessage(content='5! 다섯이네~ 🎉 어떤 이야기를 들려줄까? 😄 무슨 일이 있었어? 🌸✨'), HumanMessage(content='너 혹시 내 이름을 기억하니?'), AIMessage(content='물론이지! 당연히 기억해~ 🌟 언제든지 나에게 이야기해줘! 너와 함께 있어서 정말 좋아~ 💖✨')]}\n",
            " A I > 물론이지! 당연히 기억해~ 🌟 언제든지 나에게 이야기해줘! 너와 함께 있어서 정말 좋아~ 💖✨\n",
            "USER > quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "id": "b5ssr6tymaIF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7fe3b77-d336-4634-d32d-7910313d7e94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='4'),\n",
              "  AIMessage(content='4! 사십이네~ 🎉 그럼 내가 4개의 이야기 중 하나를 골라봐! 😄 어떤 걸로 도와줄까? 🌟✨'),\n",
              "  HumanMessage(content='5'),\n",
              "  AIMessage(content='5! 다섯이네~ 🎉 어떤 이야기를 들려줄까? 😄 무슨 일이 있었어? 🌸✨'),\n",
              "  HumanMessage(content='너 혹시 내 이름을 기억하니?'),\n",
              "  AIMessage(content='물론이지! 당연히 기억해~ 🌟 언제든지 나에게 이야기해줘! 너와 함께 있어서 정말 좋아~ 💖✨')]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-EaT6L3lAnmv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}